{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one prompt\n",
    "```\n",
    "第一个任务:\n",
    "编写一个函数名为 get_breachlist，该函数需要导入 requests、PyQuery、pandas等库。该函数的输入参数为url，实现以下内容：\n",
    "a) 使用 requests、PyQuery、pandas等库访问给定的 url，解析其中的 table标签，并将其转换为 Pandas DataFrame，将其保存为名为 df 的变量。如果 DataFrame 变量 df 是多级索引的，则删除第0层的 columns 索引。\n",
    "b) 创建 href_dic 字典，首先获取 table 标签下的所有子级 a 标签的文本值作为键，获取 a 标签的 href 属性值并加上前缀 https://resources.hse.gov.uk/convictions-history/breach/作为值。\n",
    "c) 将 href_dic 字典转换为 DataFrame，变量名为 href_df，字典的key值作为第一列, value 作为第二列, href_df 的第一列名要求与变量 df 的第一列一致.\n",
    "d) 将变量 df 与变量 href_df 按第一列对齐，进行交集合并，作为 get_breachlist 的返回值。\n",
    "e) 对函数进行修改，让其更加稳健。\n",
    "\n",
    "第二个任务:\n",
    "url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'\n",
    "url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=2&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'\n",
    "url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=3&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'\n",
    "根据上面已给出的 3个url ,分析规律并创建一个 generate_url 函数,实现生成对应的 url 字符串, 利用该方法生成 410 个网址并且 保存在 urlist 数组中.\n",
    "\n",
    "第三个任务:\n",
    "使用多线程方法,线程数量为100, 执行 get_breachlist 方法, 将数组 urlist 所有元素作为参数传入,注意传入 urlist 与保存返回值时都要用到线程锁,返回值每增加100个时, 输入提示\n",
    "\n",
    "当以上任务完成后,将所有获取到的返回值整理成一个dataframe,重置索引去重,排序操作后以 pickel 的格式保存至本地\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个任务\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "import pandas as pd\n",
    "\n",
    "def get_breachlist(url):\n",
    "    # 使用 requests 库访问给定的 url\n",
    "    response = requests.get(url)\n",
    "    # 使用 PyQuery 库解析其中的 table 标签\n",
    "    doc = pq(response.text)\n",
    "    table = doc('table')\n",
    "    # 将 table 标签转换为 Pandas DataFrame，将其保存为名为 df 的变量\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    # 如果 DataFrame 变量 df 是多级索引的，则删除第0层的 columns 索引\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.droplevel(0)\n",
    "    # 创建 href_dic 字典，首先获取 table 标签下的所有子级 a 标签的文本值作为键，获取 a 标签的 href 属性值并加上前缀 https://resources.hse.gov.uk/convictions-history/breach/作为值\n",
    "    href_dic = {}\n",
    "    for a in table.find('a'):\n",
    "        href_dic[pq(a).text()] = 'https://resources.hse.gov.uk/convictions-history/breach/' + pq(a).attr('href')\n",
    "    # 将 href_dic 字典转换为 DataFrame，变量名为 href_df，字典的key值作为第一列, value 作为第二列, href_df 的第一列名要求与变量 df 的第一列一致\n",
    "    href_df = pd.DataFrame(list(href_dic.items()), columns=[df.columns[0], 'href'])\n",
    "    # 将变量 df 与变量 href_df 按第一列对齐，进行交集合并，作为 get_breachlist 的返回值\n",
    "    result = pd.merge(df, href_df, on=df.columns[0], how='inner')\n",
    "    return result\n",
    "\n",
    "# 对函数进行修改，让其更加稳健\n",
    "def get_breachlist(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    doc = pq(response.text)\n",
    "    table = doc('table')\n",
    "    try:\n",
    "        df = pd.read_html(str(table))[0]\n",
    "    except ValueError:\n",
    "        print('No tables found')\n",
    "        return None\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.droplevel(0)\n",
    "    href_dic = {}\n",
    "    for a in table.find('a'):\n",
    "        href_dic[pq(a).text()] = 'https://resources.hse.gov.uk/convictions-history/breach/' + pq(a).attr('href')\n",
    "    href_df = pd.DataFrame(list(href_dic.items()), columns=[df.columns[0], 'href'])\n",
    "    result = pd.merge(df, href_df, on=df.columns[0], how='inner')\n",
    "    return result\n",
    "\n",
    "# 第二个任务\n",
    "def generate_url(page_num):\n",
    "    return f'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN={page_num}&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'\n",
    "\n",
    "urlist = [generate_url(i) for i in range(1, 411)]\n",
    "\n",
    "# 第三个任务\n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "results = []\n",
    "\n",
    "def get_breachlist_thread(url):\n",
    "    result = get_breachlist(url)\n",
    "    with lock:\n",
    "        results.append(result)\n",
    "        if len(results) % 100 == 0:\n",
    "            print(f'{len(results)} urls processed')\n",
    "\n",
    "threads = []\n",
    "for url in urlist:\n",
    "    t = threading.Thread(target=get_breachlist_thread, args=(url,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# 将所有获取到的返回值整理成一个dataframe,重置索引去重,排序操作后以 pickel 的格式保存至本地\n",
    "df = pd.concat(results, ignore_index=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.sort_values(by=df.columns[0], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_pickle('breachlist.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 1\n",
    "用pandas 读取本地目录下 breachlist.pkl 文件 ,保存为变量df\n",
    "取出 df 的最后一列,转为list类型 保存为 urlist\n",
    "\n",
    "task 2\n",
    "创建一个 exp_excel 方法传入参数是 url,实现以下功能:\n",
    "1 先创建局部变量 dflist cdlist  2个空数组 \n",
    "2 再创建一个子方法 get_datails ,传入参数是 url: 实现以下内容\n",
    "a) 声明使用 局部变量 dflist  与 cdlist  \n",
    "b) 先用request , pyquery 获取 url 内容并解析 table 标签, 并将其转换为 DataFrame, 类型数据 并存入局部变量 dflist中\n",
    "\n",
    "c) 另外, 我需要你遍历 table 标签下的所有子级 a 标签, 判断该标签的href  属性值是否包含 \"case_details\" 或 \"defendant_details\",如果是则将属性值的 \"..\" 替换为 \"https://resources.hse.gov.uk/convictions-history\", \n",
    "d) 当a标签 href 属性值包含 \"case_details\" 或  \"defendant_details\" 的情况时判断是否已经在 cdlist  数组中, 如果已存在则跳过,如果不存在则先存入 cdlist  数组,再执行 get_datails 方法,;\n",
    "e) 如果不包含 \"case_details\" 或 \"defendant_details\" 字符的情况下, 跳过 ; \n",
    "到此, get_datails 定义结束\n",
    "\n",
    "exp_excel  方法在上述的任何情况只要解析失败或异常时,请抛出异常返回0,  一切正常情况下 exp_excel  方法 的返回值是  dflist 元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "import pandas as pd\n",
    "\n",
    "# Read the breachlist.pkl file and save it as a dataframe variable df\n",
    "df = pd.read_pickle('breachlist.pkl')\n",
    "\n",
    "# Get the last column of df and convert it to a list, save it as urlist\n",
    "urlist = df.iloc[:, -1].tolist()\n",
    "\n",
    "# Task 2\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "def exp_excel(url):\n",
    "    # Create two empty arrays dflist and cdlist\n",
    "    dflist = []\n",
    "    cdlist = []\n",
    "    \n",
    "    # Define the get_datails function\n",
    "    def get_datails(url):\n",
    "        # Use the dflist and cdlist variables defined in the parent function\n",
    "        nonlocal dflist, cdlist\n",
    "        \n",
    "        # Use requests and pyquery to get the content of the url and parse the table tag, then convert it to a DataFrame and save it to the dflist variable\n",
    "        try:\n",
    "            html = requests.get(url).text\n",
    "            doc = pq(html)\n",
    "            table = doc('table')\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            dflist.append(df)\n",
    "        except:\n",
    "            raise Exception('Failed to parse table')\n",
    "        \n",
    "        # Traverse all child a tags under the table tag, and determine whether the href attribute value of the tag contains \"case_details\" or \"defendant_details\". If it does, replace \"..\" in the attribute value with \"https://resources.hse.gov.uk/convictions-history\"\n",
    "        for a in table.find('a'):\n",
    "            href = a.attrib.get('href')\n",
    "            if href and ('case_details' in href or 'defendant_details' in href):\n",
    "                href = href.replace('..', 'https://resources.hse.gov.uk/convictions-history')\n",
    "                \n",
    "                # If the href attribute value of the a tag contains \"case_details\" or \"defendant_details\", check whether it is already in the cdlist array. If it exists, skip it. If it does not exist, first save it to the cdlist array, and then execute the get_datails method.\n",
    "                if href not in cdlist:\n",
    "                    cdlist.append(href)\n",
    "                    get_datails(href)\n",
    "            else:\n",
    "                # If the href attribute value of the a tag does not contain \"case_details\" or \"defendant_details\", skip it.\n",
    "                continue\n",
    "    \n",
    "    # Call the get_datails function with the input url\n",
    "    try:\n",
    "        get_datails(url)\n",
    "    except:\n",
    "        raise Exception('Failed to get details')\n",
    "    \n",
    "    # Return the dflist tuple if everything is normal, or return 0 if an exception is thrown during execution\n",
    "    return tuple(dflist) if dflist else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码内容新增加, 写一个多线程任务, 对 urlist 中所有元素执行 exp_excel 方法, \n",
    "记录所有urlist 数组中元素执行的是否成功, 如果不成功能的重新传入执行,线程数量设定为50 , \n",
    "方法返回结果要用线程锁, 保存至reslist 数组中, 线程成功执行每100条 打印一次通知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import threading\n",
    "\n",
    "# Define a lock variable\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Define a function to execute the exp_excel method and save the result to the reslist array\n",
    "def execute_exp_excel(url):\n",
    "    # Use the global variables urlist and reslist\n",
    "    global urlist, reslist\n",
    "    \n",
    "    # Call the exp_excel method with the input url\n",
    "    result = exp_excel(url)\n",
    "    \n",
    "    # Use the lock variable to ensure thread safety when modifying the reslist array\n",
    "    with lock:\n",
    "        # If the result is not 0, append it to the reslist array\n",
    "        if result != 0:\n",
    "            reslist.append(result)\n",
    "        # If the result is 0, try to execute the exp_excel method again, up to 3 times\n",
    "        else:\n",
    "            for i in range(3):\n",
    "                result = exp_excel(url)\n",
    "                if result != 0:\n",
    "                    reslist.append(result)\n",
    "                    break\n",
    "    \n",
    "    # Print a notification every 100 successful executions\n",
    "    if len(reslist) % 100 == 0:\n",
    "        print('Successfully executed {} urls'.format(len(reslist)))\n",
    "\n",
    "# Define a function to create and start threads\n",
    "def create_and_start_threads():\n",
    "    # Use the global variables urlist and reslist\n",
    "    global urlist, reslist\n",
    "    \n",
    "    # Create a list to store threads\n",
    "    threads = []\n",
    "    \n",
    "    # Create and start threads for each url in urlist\n",
    "    for url in urlist:\n",
    "        # Create a thread and add it to the threads list\n",
    "        t = threading.Thread(target=execute_exp_excel, args=(url,))\n",
    "        threads.append(t)\n",
    "        \n",
    "        # If the number of threads in the threads list is equal to 50, start all threads and clear the threads list\n",
    "        if len(threads) == 50:\n",
    "            for thread in threads:\n",
    "                thread.start()\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "            threads.clear()\n",
    "    \n",
    "    # If there are any remaining threads in the threads list, start and join them\n",
    "    if threads:\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "# Create an empty reslist array\n",
    "reslist = []\n",
    "\n",
    "# Call the create_and_start_threads function to execute the exp_excel method for each url in urlist using multiple threads\n",
    "create_and_start_threads()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用pickle 的方法 保存 reslist 变量到本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 用pickle.dump()方法将relist变量保存到本地\n",
    "with open('reslist.pickle', 'wb') as f:\n",
    "    pickle.dump(reslist, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Open the file in read mode\n",
    "with open('reslist.pickle', 'rb') as f:\n",
    "    # Load the data from the file\n",
    "    ee = pickle.load(f)\n",
    "len(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
