# week2 (ç½‘ç»œæ•°æ®æ”¶é›†ä¸»é¢˜)
![Relative date](https://img.shields.io/date/1682351141?color=%239035&label=last%20update%3A&logo=anchor)

> [!DANGER]  åˆ†äº«å†…å®¹å¿«é€Ÿé¢„è§ˆï¼š
> - chatGPT å¯¹è¯åœºæ™¯ä¸‹,è‡ªæˆ‘å­¦ä¹ ä»¥ä¸‹å†…å®¹
> - python åŸºç¡€å›é¡¾ã€å®Œå–„ã€è¡¥å……3 (è¯­æ³•;æµç¨‹æ§åˆ¶;é€»è¾‘å¤„ç†;é¢å‘å¯¹è±¡ç¼–ç¨‹;é¢å‘å‡½æ•°ç¼–ç¨‹;ç­‰åŸºæœ¬æ¦‚å¿µ)
> - python ç½‘ç»œæ•°æ®æ•´ç†æˆ–æ”¶é›† (`request`;`pyquery`;`selenium`)
> - ç»“åˆ AIå·¥å…· å®Œæˆï¼Œç½‘ç«™æ•°æ®è¯·æ±‚ï¼Œæ•°æ®å“åº”è·å–ï¼›ç½‘é¡µç»“æ„ï¼Œæ ‡ç­¾è§£æç­‰ï¼›
> - è‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…· selenium è¯·æ±‚åŠ¨æ€ç½‘ç«™æ•°æ®ï¼›


> [!NOTE] python åŸºç¡€
>
> - å­—å…¸
> - æ•°ç»„
> - ç±»
> - å‡½æ•°ä¸æ–¹æ³•
>
> å®‰è£…æ”¯æŒåº“:
>
> - æ‰“å¼€ miniconda promQpt ä»¥å‘½ä»¤è¡Œæ–¹å¼å®‰è£…ä»¥ä¸‹åº“
>
> - `pip install pandas -U`
>
> - `pip install pyquery -U`
>
> - `pip install selenium -U`
>
> html æ ‡ç­¾
>
> -  F12 chrome ,æµè§ˆå™¨è°ƒè¯•å™¨
> -  æ ‡ç­¾;
> -  æ ‡ç­¾å±æ€§;
> -  æ ‡ç­¾æ–‡æœ¬å€¼;
> -  css é€‰æ‹©å™¨;



> ## case 1:  è·å–  [ Health and Safety Executive](https://www.hse.gov.uk/index.htm) æ•°æ®

!> ä»»åŠ¡:  

- 1ï¼‰è·å–ç›®æ ‡ç½‘é¡µ [Breach list](https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD) ä¸‹æ‰€æœ‰ pages çš„ Breach list è¡¨æ ¼æ•°æ®ï¼ˆè§ä¸‹å›¾Breach listï¼‰ï¼›
- 2ï¼‰ä» Breach list ä¸­è§£æå‡ºæ‰€æœ‰ Breach id çš„è¶…é“¾æ¥ï¼Œå¹¶è¿›ä¸€æ­¥è·å–è¯¥è¶…é“¾æ¥çš„ç½‘é¡µè¡¨æ ¼æ•°æ®ï¼ˆè§ä¸‹å›¾ Breach detailsï¼‰ï¼›
- 3ï¼‰å¯¹è¡¨æ ¼è¿›ä¸€æ­¥è§£æå¾—åˆ° defendant details & case details çš„è¶…é“¾æ¥å¹¶è·å–æ¬¡çº§è¡¨æ ¼æ•°æ®ã€‚

!>  è§†å±:

[Bç«™ åŒæ­¥æ›´æ–° P1: é™æ€ç½‘é¡µæ•°æ®è¯·æ±‚](https://www.bilibili.com/video/BV1Jv4y1E7KQ/?spm_id_from=333.999.0.0)

!> ç›®æ ‡ç½‘é¡µç½‘å€: 

  https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD 

![image-20230417121549418](week2.assets/image-20230417121549418.png)


!> è·å–ç½‘ç«™æ•°æ®å†…å®¹ç¤ºå›¾

![qwqw.drawio](week2.assets/qwqw.drawio.png)

!>  è®¾è®¡æ•°æ®è¯·æ±‚æµç¨‹:
```mermaid
stateDiagram-v2
    state plist{
        p1:page 1
        p2:page 2
        p3:...
        pn:page #
    }
    state blist{
        b1:case 1
        b2:case 2
        b3:...
        bn:case #
    }    
    C:Defendant datails
    B:Breach details
    D:Details for case

    state fun{
        note left of E 
            Breach details.csv
            Defendant datails.csv
            Details for case.csv
            ---
            link case #
        end note
        B  --> C:7. parse link
        B  --> D:5. parse link
		D --> E:6. save
		C --> E:8. save
        B --> E:4. save
    }
    E:save data
    F: case #
    p3 --> blist:1.parse table
    b3 --> B:3. parse link
    E--> F:9. switch
    csv:all Breach list data
    note right of csv: all Breach list.csv
    blist --> csv:2. save

```




> ## case 2: è·å–åŠ¨æ€åŠ è½½çš„æ•°æ®

!> ä»»åŠ¡:  
- 1) ä»¥chrom ä¸ºä¾‹,è‡ªåŠ¨å®‰è£…chrom driver;

- 2) åˆ©ç”¨selenium, ä¿å­˜/åŠ è½½æœ¬åœ° cookies;  

- 3) ...æœªæ›´æ–°

  
> ##  ğŸ¤” case1.prompting 

!> æé†’: ä»¥ä¸‹å†…å®¹æ˜¯ç½‘ç»œæ•°æ®è¯·æ±‚å®ç°çš„promptingè¿‡ç¨‹ã€‚
ä»¥ä¸‹æ˜¯ prompting è¿‡ç¨‹ã€‚

å°†ä½¿ç”¨ `python` åº“ï¼š`requests` `Pyqeury` `pandas`

ä»£ç ç¼–è¾‘å™¨: [cursor](https://www.cursor.so/)

---

!>  å¯¹è¯å¼ç¼–ç¨‹ã€‚å¤‡æ³¨:ä»¥ä¸‹å†…å®¹åœ¨ä»£ç å—ä¸­çš„æ˜¯ prompt å†…å®¹ï¼Œå¸¦æœ‰ğŸŸ¢ æ˜¯æ—é‡Š

### prompting 

```
#init è®¿é—®#end
è¯·ä½¿ç”¨ requests, PyQuery åº“è§£æä»¥ä¸‹ç½‘å€ä¸­çš„ table æ ‡ç­¾ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º Pandas DataFrameï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºåä¸º df çš„å˜é‡.
https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD
```

```
æ£€æŸ¥df æ˜¯å¦è¦ç›®æ ‡ç½‘é¡µæ•°æ®ä¸€è‡´ ,è¿™ä¸ªç½‘ç«™çš„æ•°ç»“æ„æ˜¯å¤šçº§ç´¢å¼•çš„, ä¸ºæ–¹ä¾¿å–å€¼å…ˆå¯¹dfè¿›è¡Œå¤„ç†#end
DataFrame å˜é‡ df æ˜¯å¤šçº§ç´¢å¼•çš„ ï¼Œè¯·å°†ç¬¬ 0 å±‚çš„ columns ç´¢å¼•åˆ é™¤ã€‚
```

```
åˆ†æç½‘é¡µ,å¼€å§‹è·å–aæ ‡ç­¾çš„æ–‡æœ¬ä¸å±æ€§å€¼#end
è·å– table æ ‡ç­¾ä¸‹çš„æ‰€æœ‰å­çº§ a æ ‡ç­¾, å¹¶æ‰“å°a æ ‡ç­¾çš„æ–‡æœ¬å€¼
```

```
ä¿®æ”¹ä»£ç #end
ä¿®æ”¹ä»£ç , å½“è·å– a æ ‡ç­¾æ–‡æœ¬æ—¶,åˆ¤æ–­æ˜¯å¦åœ¨å˜é‡ df çš„ç¬¬ä¸€åˆ—ä¸­,å¦‚æœæ˜¯çš„è¯å°†å…¶ä¿ç•™, å¹¶æ‰“å°å‡º a æ ‡ç­¾çš„ href å±æ€§å€¼
```

```
è¿™é‡ŒæŸ¥çœ‹ä»£ç æ—¶ï¼Œå‘ç°href æ²¡æœ‰åŠ å‰ç¼€ï¼Œåˆ†æç½‘é¡µç½‘å€ç»“æ„#end
ä¿®æ”¹ä»£ç ,å°†ç¬¦åˆæ¡ä»¶çš„ a æ ‡ç­¾ href å±æ€§åŠ å‰ç¼€ `https://resources.hse.gov.uk/convictions-history/breach/`
```

```
æµ‹è¯•ä¸€ä¸‹è¿™äº›è¶…é“¾æ¥çš„æ­£ç¡®æ€§,å¦‚æœæ²¡é—®é¢˜, é‚£å°† ç”¨aæ ‡ç­¾æ–‡æœ¬ä½œä¸ºkey ,hrefå±æ€§å€¼ä½œä¸ºvalues æ„å»ºä¸€ä¸ª python å­—å…¸#end
åˆ›å»ºå­—å…¸,href_dic, a æ ‡ç­¾æ–‡æœ¬ä½œä¸º key, a æ ‡ç­¾ href å±æ€§å€¼ä½œ value, æœ€åå°† href_dic è½¬ä¸ºå‘½ä¸º hrefdf çš„ pdå¯¹è±¡
```

```
åˆå¹¶åˆ—, å¯¹é½çš„å#end
ä»£ç å†…å®¹å¢åŠ ,å°† hrefdf çš„ç¬¬ä¸€åˆ—åˆ—åä¿®æ”¹ä¸º df çš„ç¬¬ä¸€åˆ—å,ä¹‹å df ä¸ hrefdf æŒ‰ç¬¬ä¸€åˆ—åˆ—å è¿›è¡Œäº¤é›†åˆå¹¶  
```

```
ç”±äºè¯¥æ–¹æ³•ä¼šç»å¸¸è¢«ç”¨åˆ°,æ‰€ä»¥åœ¨è¿™é‡Œå°†è¿™ä¸ªæ–¹æ³•å°è£…æˆå‡½æ•°æˆ–æ–¹æ³•, å…¨é€‰ä»£ç ,å†å¯¹è¯#end
ä¿®æ”¹ä»£ç , è¯·å°†è¿™æ®µä»£ç å°è£…æˆåä¸º get_breachlist çš„å‡½æ•°æ–¹æ³•,   è¾“å…¥å‚æ•°æ˜¯ url ,è¿”å›ç»“æœæ˜¯ merged_df
```

```
ä¿®æ”¹ å¢åŠ ä¸€ä¸ªæ–¹æ³•æ‰§è¡Œæ—¶çš„å¼‚å¸¸æƒ…å†µåˆ¤æ–­, å¦‚æœè§£ææ—¶ table æ²¡æœ‰è¿”å›å€¼ æˆ–ç©º æˆ–å¼‚å¸¸, åˆ™è¿”å›  None
```

```
åˆ°æ­¤,æˆ‘ä»¬å·²ç»å®Œæˆå¯¹å¯¹ç»™å®š url çš„ç½‘é¡µæ•°æ®è¯·æ±‚,å‰©ä¸‹çš„å·¥ä½œæ˜¯æ„å»º page url å°±èƒ½ç”¨ä¸€ä¸ªå¾ªç¯è¯­å¥è·å–æ‰€æœ‰pages çš„æ•°æ®ã€‚é¦–å…ˆäº¤ç»™chapGPTåˆ†æä¸‹page ç½‘é¡µçš„ç»“æ„#end
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=2&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=3&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'

åˆ†æä¸Šé¢çš„è§„å¾‹, åˆ›å»ºä¸€ä¸ªå‡½æ•°ç”Ÿæˆå¯¹åº”çš„ url å­—ç¬¦ä¸²
```

```
ç”Ÿæˆ410ä¸ªurlï¼Œ#end
ä½¿ç”¨ generate_url æ–¹æ³• ç”Ÿæˆ 410ä¸ªç½‘å€ å¹¶ä¸” ä¿å­˜åœ¨ urlist æ•°ç»„ä¸­
```

```
å¾ªç¯æ‰§è¡Œ get_breachlist æ–¹æ³•ï¼Œç›´åˆ°ç»“æŸã€‚ï¼ˆä¸²è¡Œè·å–é€Ÿåº¦æ…¢ï¼‰#end
éå† urlist æ•°ç»„, æ‰§è¡Œ get_breachlist æ–¹æ³•,å°†è¿”å›å€¼ä¿å­˜åˆ° relistæ•°ç»„ä¸­
```

```
ä¸‹é¢æˆ‘ä»¬æ”¹è¿›ä»£ç ,ä½¿ç”¨å¤šçº¿ç¨‹è¿›è¡Œçš„æ•°æ®è·å–ï¼Œå…ˆåˆ å»åˆšæ‰çš„å¾ªç¯è¯­å¥#end
ç”¨å¤šçº¿ç¨‹æ–¹æ³• å¯åŠ¨ get_breachlist æ–¹æ³•,ä¼ å…¥ urlist ä¸­çš„ urlç›´åˆ°urlistä¸ºç©º
```

```
ä¿®æ”¹ä»£ç , ä¿å­˜è¿”å›ç»“æœæ—¶ä½¿ç”¨çº¿ç¨‹é”,å½“ç»“æœæ¯å¢åŠ 50ä¸ªæ—¶é€šçŸ¥æˆ‘ä¿®æ”¹ä»£ç , ä¿å­˜è¿”å›ç»“æœæ—¶ä½¿ç”¨çº¿ç¨‹é”
```

```
ä¿å­˜ç»“æœï¼Œåˆ°æœ¬åœ°*.pkl#end
å°†pandas ç±»å‹çš„å˜é‡ df ,ä¿å­˜ä¸º  breachlist çš„pkl æ–‡ä»¶
```

###  one prompt 

```
#init{1-15}
ç”¨ä¸€ä¸ª prompt æ€»ç»“ä»¥ä¸Šæ­¥éª¤ #end
ç¬¬ä¸€ä¸ªä»»åŠ¡:
ç¼–å†™ä¸€ä¸ªå‡½æ•°åä¸º get_breachlistï¼Œè¯¥å‡½æ•°éœ€è¦å¯¼å…¥ requestsã€PyQueryã€pandasç­‰åº“ã€‚è¯¥å‡½æ•°çš„è¾“å…¥å‚æ•°ä¸ºurlï¼Œå®ç°ä»¥ä¸‹å†…å®¹ï¼š
a) ä½¿ç”¨ requestsã€PyQueryã€pandasç­‰åº“è®¿é—®ç»™å®šçš„ urlï¼Œè§£æå…¶ä¸­çš„ tableæ ‡ç­¾ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º Pandas DataFrameï¼Œå°†å…¶ä¿å­˜ä¸ºåä¸º df çš„å˜é‡ã€‚å¦‚æœ DataFrame å˜é‡ df æ˜¯å¤šçº§ç´¢å¼•çš„ï¼Œåˆ™åˆ é™¤ç¬¬0å±‚çš„ columns ç´¢å¼•ã€‚
b) åˆ›å»º href_dic å­—å…¸ï¼Œé¦–å…ˆè·å– table æ ‡ç­¾ä¸‹çš„æ‰€æœ‰å­çº§ a æ ‡ç­¾çš„æ–‡æœ¬å€¼ä½œä¸ºé”®ï¼Œè·å– a æ ‡ç­¾çš„ href å±æ€§å€¼å¹¶åŠ ä¸Šå‰ç¼€ https://resources.hse.gov.uk/convictions-history/breach/ä½œä¸ºå€¼ã€‚
c) å°† href_dic å­—å…¸è½¬æ¢ä¸º DataFrameï¼Œå˜é‡åä¸º href_dfï¼Œå­—å…¸çš„keyå€¼ä½œä¸ºç¬¬ä¸€åˆ—, value ä½œä¸ºç¬¬äºŒåˆ—, href_df çš„ç¬¬ä¸€åˆ—åè¦æ±‚ä¸å˜é‡ df çš„ç¬¬ä¸€åˆ—ä¸€è‡´.
d) å°†å˜é‡ df ä¸å˜é‡ href_df æŒ‰ç¬¬ä¸€åˆ—å¯¹é½ï¼Œè¿›è¡Œäº¤é›†åˆå¹¶ï¼Œä½œä¸º get_breachlist çš„è¿”å›å€¼ã€‚
e) å¯¹å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œè®©å…¶æ›´åŠ ç¨³å¥ã€‚

ç¬¬äºŒä¸ªä»»åŠ¡:
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=1&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=2&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'
url = 'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN=3&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'
æ ¹æ®ä¸Šé¢å·²ç»™å‡ºçš„ 3ä¸ªurl ,åˆ†æè§„å¾‹å¹¶åˆ›å»ºä¸€ä¸ª generate_url å‡½æ•°,å®ç°ç”Ÿæˆå¯¹åº”çš„ url å­—ç¬¦ä¸², åˆ©ç”¨è¯¥æ–¹æ³•ç”Ÿæˆ 410 ä¸ªç½‘å€å¹¶ä¸” ä¿å­˜åœ¨ urlist æ•°ç»„ä¸­.

ç¬¬ä¸‰ä¸ªä»»åŠ¡:
ä½¿ç”¨å¤šçº¿ç¨‹æ–¹æ³•,çº¿ç¨‹æ•°é‡ä¸º100, æ‰§è¡Œ get_breachlist æ–¹æ³•, å°†æ•°ç»„ urlist æ‰€æœ‰å…ƒç´ ä½œä¸ºå‚æ•°ä¼ å…¥,æ³¨æ„ä¼ å…¥ urlist ä¸ä¿å­˜è¿”å›å€¼æ—¶éƒ½è¦ç”¨åˆ°çº¿ç¨‹é”,è¿”å›å€¼æ¯å¢åŠ 100ä¸ªæ—¶, è¾“å…¥æç¤º

å½“ä»¥ä¸Šä»»åŠ¡å®Œæˆå,å°†æ‰€æœ‰è·å–åˆ°çš„è¿”å›å€¼æ•´ç†æˆä¸€ä¸ªdataframe,é‡ç½®ç´¢å¼•å»é‡,æ’åºæ“ä½œåä»¥ pickel çš„æ ¼å¼ä¿å­˜è‡³æœ¬åœ°
```
<br>

>[!TIP]
```python
# ç¬¬ä¸€ä¸ªä»»åŠ¡
import requests
from pyquery import PyQuery as pq
import pandas as pd

def get_breachlist(url):
    # ä½¿ç”¨ requests åº“è®¿é—®ç»™å®šçš„ url
    response = requests.get(url)
    # ä½¿ç”¨ PyQuery åº“è§£æå…¶ä¸­çš„ table æ ‡ç­¾
    doc = pq(response.text)
    table = doc('table')
    # å°† table æ ‡ç­¾è½¬æ¢ä¸º Pandas DataFrameï¼Œå°†å…¶ä¿å­˜ä¸ºåä¸º df çš„å˜é‡
    df = pd.read_html(str(table))[0]
    # å¦‚æœ DataFrame å˜é‡ df æ˜¯å¤šçº§ç´¢å¼•çš„ï¼Œåˆ™åˆ é™¤ç¬¬0å±‚çš„ columns ç´¢å¼•
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.droplevel(0)
    # åˆ›å»º href_dic å­—å…¸ï¼Œé¦–å…ˆè·å– table æ ‡ç­¾ä¸‹çš„æ‰€æœ‰å­çº§ a æ ‡ç­¾çš„æ–‡æœ¬å€¼ä½œä¸ºé”®ï¼Œè·å– a æ ‡ç­¾çš„ href å±æ€§å€¼å¹¶åŠ ä¸Šå‰ç¼€ https://resources.hse.gov.uk/convictions-history/breach/ä½œä¸ºå€¼
    href_dic = {}
    for a in table.find('a'):
        href_dic[pq(a).text()] = 'https://resources.hse.gov.uk/convictions-history/breach/' + pq(a).attr('href')
    # å°† href_dic å­—å…¸è½¬æ¢ä¸º DataFrameï¼Œå˜é‡åä¸º href_dfï¼Œå­—å…¸çš„keyå€¼ä½œä¸ºç¬¬ä¸€åˆ—, value ä½œä¸ºç¬¬äºŒåˆ—, href_df çš„ç¬¬ä¸€åˆ—åè¦æ±‚ä¸å˜é‡ df çš„ç¬¬ä¸€åˆ—ä¸€è‡´
    href_df = pd.DataFrame(list(href_dic.items()), columns=[df.columns[0], 'href'])
    # å°†å˜é‡ df ä¸å˜é‡ href_df æŒ‰ç¬¬ä¸€åˆ—å¯¹é½ï¼Œè¿›è¡Œäº¤é›†åˆå¹¶ï¼Œä½œä¸º get_breachlist çš„è¿”å›å€¼
    result = pd.merge(df, href_df, on=df.columns[0], how='inner')
    return result

# å¯¹å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œè®©å…¶æ›´åŠ ç¨³å¥
def get_breachlist(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(e)
        return None
    doc = pq(response.text)
    table = doc('table')
    try:
        df = pd.read_html(str(table))[0]
    except ValueError:
        print('No tables found')
        return None
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.droplevel(0)
    href_dic = {}
    for a in table.find('a'):
        href_dic[pq(a).text()] = 'https://resources.hse.gov.uk/convictions-history/breach/' + pq(a).attr('href')
    href_df = pd.DataFrame(list(href_dic.items()), columns=[df.columns[0], 'href'])
    result = pd.merge(df, href_df, on=df.columns[0], how='inner')
    return result

# ç¬¬äºŒä¸ªä»»åŠ¡
def generate_url(page_num):
    return f'https://resources.hse.gov.uk/convictions-history/breach/breach_list.asp?PN={page_num}&ST=B&EO=LIKE&SN=F&SF=DN&SV=&SO=DHD'

urlist = [generate_url(i) for i in range(1, 411)]

# ç¬¬ä¸‰ä¸ªä»»åŠ¡
import threading

lock = threading.Lock()
results = []

def get_breachlist_thread(url):
    result = get_breachlist(url)
    with lock:
        results.append(result)
        if len(results) % 100 == 0:
            print(f'{len(results)} urls processed')

threads = []
for url in urlist:
    t = threading.Thread(target=get_breachlist_thread, args=(url,))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

# å°†æ‰€æœ‰è·å–åˆ°çš„è¿”å›å€¼æ•´ç†æˆä¸€ä¸ªdataframe,é‡ç½®ç´¢å¼•å»é‡,æ’åºæ“ä½œåä»¥ pickel çš„æ ¼å¼ä¿å­˜è‡³æœ¬åœ°
df = pd.concat(results, ignore_index=True)
df.drop_duplicates(inplace=True)
df.sort_values(by=df.columns[0], inplace=True)
df.reset_index(drop=True, inplace=True)
df.to_pickle('breachlist.pkl')
```


```

è·å–äºŒçº§è¡¨ï¼Œæ‰€æœ‰ case å¯¹åº”çš„ `breach details` `details for case#` `Defendant details` #end
task 1
ç”¨pandas è¯»å–æœ¬åœ°ç›®å½•ä¸‹ breachlist.pkl æ–‡ä»¶ ,ä¿å­˜ä¸ºå˜é‡df
å–å‡º df çš„æœ€åä¸€åˆ—,è½¬ä¸ºlistç±»å‹ ä¿å­˜ä¸º urlist

task 2
åˆ›å»ºä¸€ä¸ª exp_excel æ–¹æ³•ä¼ å…¥å‚æ•°æ˜¯ url,å®ç°ä»¥ä¸‹åŠŸèƒ½:
1 å…ˆåˆ›å»ºå±€éƒ¨å˜é‡ dflist cdlist  2ä¸ªç©ºæ•°ç»„ 
2 å†åˆ›å»ºä¸€ä¸ªå­æ–¹æ³• get_datails ,ä¼ å…¥å‚æ•°æ˜¯ url: å®ç°ä»¥ä¸‹å†…å®¹
a) å£°æ˜ä½¿ç”¨ å±€éƒ¨å˜é‡ dflist  ä¸ cdlist  
b) å…ˆç”¨request , pyquery è·å– url å†…å®¹å¹¶è§£æ table æ ‡ç­¾, å¹¶å°†å…¶è½¬æ¢ä¸º DataFrame, ç±»å‹æ•°æ® å¹¶å­˜å…¥å±€éƒ¨å˜é‡ dflistä¸­

c) å¦å¤–, æˆ‘éœ€è¦ä½ éå† table æ ‡ç­¾ä¸‹çš„æ‰€æœ‰å­çº§ a æ ‡ç­¾, åˆ¤æ–­è¯¥æ ‡ç­¾çš„href  å±æ€§å€¼æ˜¯å¦åŒ…å« "case_details" æˆ– "defendant_details",å¦‚æœæ˜¯åˆ™å°†å±æ€§å€¼çš„ ".." æ›¿æ¢ä¸º "https://resources.hse.gov.uk/convictions-history", 
d) å½“aæ ‡ç­¾ href å±æ€§å€¼åŒ…å« "case_details" æˆ–  "defendant_details" çš„æƒ…å†µæ—¶åˆ¤æ–­æ˜¯å¦å·²ç»åœ¨ cdlist  æ•°ç»„ä¸­, å¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡,å¦‚æœä¸å­˜åœ¨åˆ™å…ˆå­˜å…¥ cdlist  æ•°ç»„,å†æ‰§è¡Œ get_datails æ–¹æ³•,;
e) å¦‚æœä¸åŒ…å« "case_details" æˆ– "defendant_details" å­—ç¬¦çš„æƒ…å†µä¸‹, è·³è¿‡ ; 
åˆ°æ­¤, get_datails å®šä¹‰ç»“æŸ

exp_excel  æ–¹æ³•åœ¨ä¸Šè¿°çš„ä»»ä½•æƒ…å†µåªè¦è§£æå¤±è´¥æˆ–å¼‚å¸¸æ—¶,è¯·æŠ›å‡ºå¼‚å¸¸è¿”å›0,  ä¸€åˆ‡æ­£å¸¸æƒ…å†µä¸‹ exp_excel  æ–¹æ³• çš„è¿”å›å€¼æ˜¯  dflist å…ƒç»„

```

```
ä»£ç å†…å®¹æ–°å¢åŠ , å†™ä¸€ä¸ªå¤šçº¿ç¨‹ä»»åŠ¡, å¯¹ urlist ä¸­æ‰€æœ‰å…ƒç´ æ‰§è¡Œ exp_excel æ–¹æ³•, 
è®°å½•æ‰€æœ‰urlist æ•°ç»„ä¸­å…ƒç´ æ‰§è¡Œçš„æ˜¯å¦æˆåŠŸ, å¦‚æœä¸æˆåŠŸèƒ½çš„é‡æ–°ä¼ å…¥æ‰§è¡Œ,çº¿ç¨‹æ•°é‡è®¾å®šä¸º50 , 
æ–¹æ³•è¿”å›ç»“æœè¦ç”¨çº¿ç¨‹é”, ä¿å­˜è‡³reslist æ•°ç»„ä¸­, çº¿ç¨‹æˆåŠŸæ‰§è¡Œæ¯100æ¡ æ‰“å°ä¸€æ¬¡é€šçŸ¥
```

```
ç”¨pickle çš„æ–¹æ³• ä¿å­˜ relist å˜é‡åˆ°æœ¬åœ°
```

!> æœ€ç»ˆå®Œæ•´ä»£ç 

```python
# Task 1
import pandas as pd

# Read the breachlist.pkl file and save it as a dataframe variable df
df = pd.read_pickle('breachlist.pkl')

# Get the last column of df and convert it to a list, save it as urlist
urlist = df.iloc[:, -1].tolist()

# Task 2
import requests
from pyquery import PyQuery as pq

def exp_excel(url):
    # Create two empty arrays dflist and cdlist
    dflist = []
    cdlist = []
    
    # Define the get_datails function
    def get_datails(url):
        # Use the dflist and cdlist variables defined in the parent function
        nonlocal dflist, cdlist
        
        # Use requests and pyquery to get the content of the url and parse the table tag, then convert it to a DataFrame and save it to the dflist variable
        try:
            html = requests.get(url).text
            doc = pq(html)
            table = doc('table')
            df = pd.read_html(str(table))[0]
            dflist.append(df)
        except:
            raise Exception('Failed to parse table')
        
        # Traverse all child a tags under the table tag, and determine whether the href attribute value of the tag contains "case_details" or "defendant_details". If it does, replace ".." in the attribute value with "https://resources.hse.gov.uk/convictions-history"
        for a in table.find('a'):
            href = a.attrib.get('href')
            if href and ('case_details' in href or 'defendant_details' in href):
                href = href.replace('..', 'https://resources.hse.gov.uk/convictions-history')
                
                # If the href attribute value of the a tag contains "case_details" or "defendant_details", check whether it is already in the cdlist array. If it exists, skip it. If it does not exist, first save it to the cdlist array, and then execute the get_datails method.
                if href not in cdlist:
                    cdlist.append(href)
                    get_datails(href)
            else:
                # If the href attribute value of the a tag does not contain "case_details" or "defendant_details", skip it.
                continue
    
    # Call the get_datails function with the input url
    try:
        get_datails(url)
    except:
        raise Exception('Failed to get details')
    
    # Return the dflist tuple if everything is normal, or return 0 if an exception is thrown during execution
    return tuple(dflist) if dflist else 0

import threading

# Define a lock variable
lock = threading.Lock()

# Define a function to execute the exp_excel method and save the result to the reslist array
def execute_exp_excel(url):
    # Use the global variables urlist and reslist
    global urlist, reslist
    
    # Call the exp_excel method with the input url
    result = exp_excel(url)
    
    # Use the lock variable to ensure thread safety when modifying the reslist array
    with lock:
        # If the result is not 0, append it to the reslist array
        if result != 0:
            reslist.append(result)
        # If the result is 0, try to execute the exp_excel method again, up to 3 times
        else:
            for i in range(3):
                result = exp_excel(url)
                if result != 0:
                    reslist.append(result)
                    break
    
    # Print a notification every 100 successful executions
    if len(reslist) % 100 == 0:
        print('Successfully executed {} urls'.format(len(reslist)))

# Define a function to create and start threads
def create_and_start_threads():
    # Use the global variables urlist and reslist
    global urlist, reslist
    
    # Create a list to store threads
    threads = []
    
    # Create and start threads for each url in urlist
    for url in urlist:
        # Create a thread and add it to the threads list
        t = threading.Thread(target=execute_exp_excel, args=(url,))
        threads.append(t)
        
        # If the number of threads in the threads list is equal to 50, start all threads and clear the threads list
        if len(threads) == 50:
            for thread in threads:
                thread.start()
            for thread in threads:
                thread.join()
            threads.clear()
    
    # If there are any remaining threads in the threads list, start and join them
    if threads:
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()

# Create an empty reslist array
reslist = []

# Call the create_and_start_threads function to execute the exp_excel method for each url in urlist using multiple threads
create_and_start_threads()

import pickle

# ç”¨pickle.dump()æ–¹æ³•å°†relistå˜é‡ä¿å­˜åˆ°æœ¬åœ°
with open('relist.pickle', 'wb') as f:
    pickle.dump(reslist, f)
```

> ##  ğŸ¤” case2.prompting


ğŸŸ¢1 ä½¿ç”¨ selenium æ—¶,ä»¥ chrome ä¸ºä¾‹, éœ€è¦æ›´æ–° chrome driver çš„æœ€æ–°ç‰ˆ.
```
#init{1}
ç”¨åˆ°python çš„ seleniumæ—¶ éœ€è¦ chrome driver è¿™ä¸ªæœ‰ä»€ä¹ˆåº“å¯ä»¥è‡ªåŠ¨æ›´æ–°
```
```
ä½¿ç”¨ selenium ç™»é™† ä»¥ä¸‹ç½‘å€, ç»™æˆ‘10ç§’æ—¶é—´ç”¨äºç™»é™†,   ä¹‹åä½ åˆ›å»ºè¯»å– ä¸ä¿å­˜cookies åˆ°æœ¬åœ°ç›®å½•çš„2ä¸ªæ–¹æ³•,    ç¬¬ä¸€æ¬¡æ—¶, ä½ å°†ä¿å­˜æˆ‘çš„ç™»é™† cookiesä¿¡æ¯,
```

(selenium çš„å¾…è¡¥å……)


